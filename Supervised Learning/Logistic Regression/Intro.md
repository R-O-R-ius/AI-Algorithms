## Logistic Regression

Logistic regression predictions are discrete values (i.e., whether a student passed/failed) after applying a transformation function.
Logistic regression is best suited for binary classification: data sets where y = 0 or 1, where 1 denotes the default class.
For example, in predicting whether an event will occur or not, there are only two possibilities: that it occurs (which we denote as 1) or that it does not (0).
So if we were predicting whether a patient was sick, we would label sick patients using the value of 1 in our data set.
Logistic regression is named after the transformation function it uses, which is called the logistic function h(x)= 1/ (1 + ex). This forms an S-shaped curve.

In logistic regression, the output takes the form of probabilities of the default class (unlike linear regression, where the output is directly produced).
As it is a probability, the output lies in the range of 0-1.
So, for example, if weâ€™re trying to predict whether patients are sick, we already know that sick patients are denoted as 1,
so if our algorithm assigns the score of 0.98 to a patient, it thinks that patient is quite likely to be sick.

This output (y-value) is generated by log transforming the x-value, using the logistic function h(x)= 1/ (1 + e^ -x).
A threshold is then applied to force this probability into a binary classification.

## Logistic Regression Equation

The logistic regression equation P(x) = e^(b0 + b1x)/(1 + e(b0 + b1x)) can be transformed into ln(p(x)/1-p(x)) = b0 + b1x.
The goal of logistic regression is to use the training data to find the values of coefficients b0 and b1
such that it will minimize the error between the predicted outcome and the actual outcome.
These coefficients are estimated using the technique of Maximum Likelihood Estimation.
